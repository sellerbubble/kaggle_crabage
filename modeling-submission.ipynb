{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install scikit-lego","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-11-08T14:18:39.300806Z","iopub.execute_input":"2023-11-08T14:18:39.301269Z","iopub.status.idle":"2023-11-08T14:18:51.980338Z","shell.execute_reply.started":"2023-11-08T14:18:39.301238Z","shell.execute_reply":"2023-11-08T14:18:51.979059Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Collecting scikit-lego\n  Downloading scikit_lego-0.6.16-py2.py3-none-any.whl (229 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.1/229.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: scikit-learn>=1.0 in /opt/conda/lib/python3.10/site-packages (from scikit-lego) (1.2.2)\nRequirement already satisfied: pandas>=1.1.5 in /opt/conda/lib/python3.10/site-packages (from scikit-lego) (1.5.3)\nRequirement already satisfied: patsy>=0.5.1 in /opt/conda/lib/python3.10/site-packages (from scikit-lego) (0.5.3)\nCollecting autograd>=1.2 (from scikit-lego)\n  Downloading autograd-1.6.2-py3-none-any.whl (49 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: Deprecated>=1.2.6 in /opt/conda/lib/python3.10/site-packages (from scikit-lego) (1.2.13)\nRequirement already satisfied: umap-learn>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from scikit-lego) (0.5.3)\nRequirement already satisfied: numpy>=1.12 in /opt/conda/lib/python3.10/site-packages (from autograd>=1.2->scikit-lego) (1.23.5)\nRequirement already satisfied: future>=0.15.2 in /opt/conda/lib/python3.10/site-packages (from autograd>=1.2->scikit-lego) (0.18.3)\nRequirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.10/site-packages (from Deprecated>=1.2.6->scikit-lego) (1.14.1)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.5->scikit-lego) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.5->scikit-lego) (2023.3)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from patsy>=0.5.1->scikit-lego) (1.16.0)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.0->scikit-lego) (1.10.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.0->scikit-lego) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.0->scikit-lego) (3.1.0)\nRequirement already satisfied: numba>=0.49 in /opt/conda/lib/python3.10/site-packages (from umap-learn>=0.4.6->scikit-lego) (0.56.4)\nRequirement already satisfied: pynndescent>=0.5 in /opt/conda/lib/python3.10/site-packages (from umap-learn>=0.4.6->scikit-lego) (0.5.10)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from umap-learn>=0.4.6->scikit-lego) (4.64.1)\nRequirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.49->umap-learn>=0.4.6->scikit-lego) (0.39.1)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from numba>=0.49->umap-learn>=0.4.6->scikit-lego) (59.8.0)\nInstalling collected packages: autograd, scikit-lego\nSuccessfully installed autograd-1.6.2 scikit-lego-0.6.16\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd; pd.set_option('display.max_columns', 100)\nimport numpy as np\n\nfrom tqdm.notebook import tqdm\n\nimport matplotlib.pyplot as plt; plt.style.use('ggplot')\nimport seaborn as sns\nimport plotly.express as px\n\nfrom sklearn.tree import DecisionTreeRegressor, plot_tree\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.linear_model import Ridge, RidgeCV, Lasso, LassoCV\nfrom sklearn.model_selection import KFold, StratifiedKFold, train_test_split, GridSearchCV, RepeatedKFold, RepeatedStratifiedKFold\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom sklearn.inspection import PartialDependenceDisplay\nfrom sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor, GradientBoostingRegressor, ExtraTreesRegressor\nfrom sklearn.svm import SVR\nfrom lightgbm import LGBMRegressor\nfrom xgboost import XGBRegressor\nfrom catboost import CatBoostRegressor\nfrom sklego.linear_model import LADRegression","metadata":{"execution":{"iopub.status.busy":"2023-11-08T14:19:03.137207Z","iopub.execute_input":"2023-11-08T14:19:03.137584Z","iopub.status.idle":"2023-11-08T14:19:07.693062Z","shell.execute_reply.started":"2023-11-08T14:19:03.137551Z","shell.execute_reply":"2023-11-08T14:19:07.692197Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/playground-series-s3e16/train.csv')\ntest = pd.read_csv('../input/playground-series-s3e16/test.csv')\noriginal = pd.read_csv('../input/crab-age-prediction/CrabAgePrediction.csv')\nsubmission = pd.read_csv('../input/playground-series-s3e16/sample_submission.csv')\n\nprint('The dimension of the train synthetic dataset is:', train.shape)\nprint('The dimension of the test synthetic dataset is:', test.shape)\nprint('The dimension of the orginal dataset is:', original.shape)\nprint('The dimension of the submission dataset is:', submission.shape)","metadata":{"execution":{"iopub.status.busy":"2023-11-08T14:19:12.818973Z","iopub.execute_input":"2023-11-08T14:19:12.819633Z","iopub.status.idle":"2023-11-08T14:19:13.167022Z","shell.execute_reply.started":"2023-11-08T14:19:12.819602Z","shell.execute_reply":"2023-11-08T14:19:13.166114Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"The dimension of the train synthetic dataset is: (74051, 10)\nThe dimension of the test synthetic dataset is: (49368, 9)\nThe dimension of the orginal dataset is: (3893, 9)\nThe dimension of the submission dataset is: (49368, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"le = LabelEncoder()\n\ntrain['generated'] = 1\noriginal['generated'] = 0\ntest['generated'] = 1\n\ntrain.drop(columns = 'id', axis = 1, inplace = True)\n\ntrain = pd.concat([train, original], axis = 0).reset_index(drop = True)\ntrain['Sex'] = le.fit_transform(train['Sex'])","metadata":{"execution":{"iopub.status.busy":"2023-11-08T14:19:18.521223Z","iopub.execute_input":"2023-11-08T14:19:18.521580Z","iopub.status.idle":"2023-11-08T14:19:18.573025Z","shell.execute_reply.started":"2023-11-08T14:19:18.521549Z","shell.execute_reply":"2023-11-08T14:19:18.572290Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"X = train.drop(columns = ['Age'], axis = 1)\nY = train['Age']\n\ntest_baseline = test.drop(columns = ['id'], axis = 1)\ntest_baseline['Sex'] = le.transform(test_baseline['Sex'])\n\ngb_cv_scores, gb_preds = list(), list()\nhist_cv_scores, hist_preds = list(), list()\nlgb_cv_scores, lgb_preds = list(), list()\nxgb_cv_scores, xgb_preds = list(), list()\nens_cv_scores, ens_preds = list(), list()","metadata":{"execution":{"iopub.status.busy":"2023-11-08T14:19:21.664288Z","iopub.execute_input":"2023-11-08T14:19:21.664648Z","iopub.status.idle":"2023-11-08T14:19:21.688743Z","shell.execute_reply.started":"2023-11-08T14:19:21.664618Z","shell.execute_reply":"2023-11-08T14:19:21.687792Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"a = sum(Y == 20)\nprint(a)","metadata":{"execution":{"iopub.status.busy":"2023-11-08T14:38:49.980756Z","iopub.execute_input":"2023-11-08T14:38:49.981541Z","iopub.status.idle":"2023-11-08T14:38:49.996613Z","shell.execute_reply.started":"2023-11-08T14:38:49.981499Z","shell.execute_reply":"2023-11-08T14:38:49.995507Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"438\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Next we proceed to build a couple of baseline models as shown below. Also, we ensemble the baseline model predictions using least absolute deviation regression.","metadata":{}},{"cell_type":"code","source":"'''\nX = train.drop(columns = ['Age'], axis = 1)\nY = train['Age']\n\ntest_baseline = test.drop(columns = ['id'], axis = 1)\ntest_baseline['Sex'] = le.transform(test_baseline['Sex'])\n\ngb_cv_scores, gb_preds = list(), list()\nhist_cv_scores, hist_preds = list(), list()\nlgb_cv_scores, lgb_preds = list(), list()\nxgb_cv_scores, xgb_preds = list(), list()\nens_cv_scores, ens_preds = list(), list()\n\nskf = KFold(n_splits = 1, random_state = 42, shuffle = True)\n    \nfor i, (train_ix, test_ix) in enumerate(skf.split(X, Y)):\n        \n    X_train, X_test = X.iloc[train_ix], X.iloc[test_ix]\n    Y_train, Y_test = Y.iloc[train_ix], Y.iloc[test_ix]\n    \n    print('---------------------------------------------------------------')\n    \n    ######################\n    ## GradientBoosting ##\n    ######################\n        \n    gb_md = GradientBoostingRegressor(loss = 'absolute_error',\n                                      n_estimators = 1000, \n                                      max_depth = 8, \n                                      learning_rate = 0.01,\n                                      min_samples_split = 10, \n                                      min_samples_leaf = 20).fit(X_train, Y_train) \n    \n    gb_pred_1 = gb_md.predict(X_test[X_test['generated'] == 1])\n    gb_pred_2 = gb_md.predict(test_baseline)\n            \n    gb_score_fold = mean_absolute_error(Y_test[X_test['generated'] == 1], gb_pred_1)\n    gb_cv_scores.append(gb_score_fold)\n    gb_preds.append(gb_pred_2)\n    \n    print('Fold', i, '==> GradientBoositng oof MAE is ==>', gb_score_fold)\n    \n    \n    ##########################\n    ## HistGradientBoosting ##\n    ##########################\n        \n    hist_md = HistGradientBoostingRegressor(loss = 'absolute_error',\n                                            l2_regularization = 0.01,\n                                            early_stopping = False,\n                                            learning_rate = 0.01,\n                                            max_iter = 1000,\n                                            max_depth = 15,\n                                            max_bins = 255,\n                                            min_samples_leaf = 70,\n                                            max_leaf_nodes = 115).fit(X_train, Y_train)\n    \n    hist_pred_1 = hist_md.predict(X_test[X_test['generated'] == 1])\n    hist_pred_2 = hist_md.predict(test_baseline)\n\n    hist_score_fold = mean_absolute_error(Y_test[X_test['generated'] == 1], hist_pred_1)\n    hist_cv_scores.append(hist_score_fold)\n    hist_preds.append(hist_pred_2)\n    \n    print('Fold', i, '==> HistGradient oof MAE is ==>', hist_score_fold)\n        \n    ##############\n    ## LightGBM ##\n    ##############\n        \n    lgb_md = LGBMRegressor(objective = 'mae', \n                           n_estimators = 1000,\n                           max_depth = 15,\n                           learning_rate = 0.01,\n                           num_leaves = 105,\n                           reg_alpha = 8,\n                           reg_lambda = 3,\n                           subsample = 0.6,\n                           colsample_bytree = 0.8,\n                           device = 'gpu').fit(X_train, Y_train)\n    \n    lgb_pred_1 = lgb_md.predict(X_test[X_test['generated'] == 1])\n    lgb_pred_2 = lgb_md.predict(test_baseline)\n\n    lgb_score_fold = mean_absolute_error(Y_test[X_test['generated'] == 1], lgb_pred_1)    \n    lgb_cv_scores.append(lgb_score_fold)\n    lgb_preds.append(lgb_pred_2)\n    \n    print('Fold', i, '==> LightGBM oof MAE is ==>', lgb_score_fold)\n        \n    #############\n    ## XGBoost ##\n    #############\n        \n    xgb_md = XGBRegressor(objective = 'reg:pseudohubererror',\n                          tree_method = 'gpu_hist',\n                          colsample_bytree = 0.9, \n                          gamma = 0.65, \n                          learning_rate = 0.01, \n                          max_depth = 7, \n                          min_child_weight = 20, \n                          n_estimators = 1000, \n                          subsample = 0.7).fit(X_train, Y_train)\n    \n    xgb_pred_1 = xgb_md.predict(X_test[X_test['generated'] == 1])\n    xgb_pred_2 = xgb_md.predict(test_baseline)\n\n    xgb_score_fold = mean_absolute_error(Y_test[X_test['generated'] == 1], xgb_pred_1)    \n    xgb_cv_scores.append(xgb_score_fold)\n    xgb_preds.append(xgb_pred_2)\n    \n    print('Fold', i, '==> XGBoost oof MAE is ==>', xgb_score_fold)\n    \n    ##################\n    ## LAD Ensemble ##\n    ##################\n    \n    x = pd.DataFrame({'GBC':gb_pred_1,  'hist': hist_pred_1, 'lgb': lgb_pred_1, 'xgb': xgb_pred_1})\n    y = Y_test[X_test['generated'] == 1]\n    \n    lad_md = LADRegression().fit(x, y)\n    lad_pred = lad_md.predict(x)\n    \n    x_test = pd.DataFrame({'GBC':gb_pred_2,  'hist': hist_pred_2, 'lgb': lgb_pred_2, 'xgb': xgb_pred_2})\n    lad_pred_test = lad_md.predict(x_test)\n        \n    ens_score = mean_absolute_error(y, lad_pred)\n    ens_cv_scores.append(ens_score)\n    ens_preds.append(lad_pred_test)\n    \n    print('Fold', i, '==> LAD ensemble oof MAE is ==>', ens_score)\n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\nfor i in [700,1000,1200]:\n    for j in [8,10,12]:\n        for k in [10,20,30,50]:\n            for t in [10,20,30,50]:\n                gb_md = GradientBoostingRegressor(loss = 'absolute_error',\n                                                      n_estimators = i, \n                                                      max_depth = 8, \n                                                      learning_rate = 0.01,\n                                                      min_samples_split = k, \n                                                      min_samples_leaf =t ).fit(X_train, Y_train) \n                gb_pred_1 = gb_md.predict(X_test[X_test['generated'] == 1])\n                gb_pred_2 = gb_md.predict(test_baseline)\n\n                gb_score_fold = mean_absolute_error(Y_test[X_test['generated'] == 1], gb_pred_1)\n                gb_cv_scores.append(gb_score_fold)\n                gb_preds.append(gb_pred_2)\n                print('i=%d,j=%d,k=%d，t=%d,score=%.10f'%(i,j,k,t,gb_score_fold))\n'''","metadata":{"execution":{"iopub.status.busy":"2023-11-04T10:42:31.094846Z","iopub.execute_input":"2023-11-04T10:42:31.095242Z","iopub.status.idle":"2023-11-04T11:08:04.815134Z","shell.execute_reply.started":"2023-11-04T10:42:31.095208Z","shell.execute_reply":"2023-11-04T11:08:04.813645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nfor i in [500,700,1000,1200,1500]:\n    for k in [50,70,100,120,150]:\n        hist_md = HistGradientBoostingRegressor(loss = 'absolute_error',\n                                                l2_regularization = 0.01,\n                                                early_stopping = False,\n                                                learning_rate = 0.01,\n                                                max_iter = i,\n                                                max_depth = 8,\n                                                max_bins = 255,\n                                                min_samples_leaf = k,\n                                                max_leaf_nodes = k).fit(X_train, Y_train)\n\n        hist_pred_1 = hist_md.predict(X_test[X_test['generated'] == 1])\n        hist_pred_2 = hist_md.predict(test_baseline)\n\n        hist_score_fold = mean_absolute_error(Y_test[X_test['generated'] == 1], hist_pred_1)\n        hist_cv_scores.append(hist_score_fold)\n        hist_preds.append(hist_pred_2)\n        print('i=%d,k=%d，score=%.10f'%(i,k,hist_score_fold))\n'''","metadata":{"execution":{"iopub.status.busy":"2023-11-04T08:15:29.849863Z","iopub.execute_input":"2023-11-04T08:15:29.850249Z","iopub.status.idle":"2023-11-04T08:25:11.022778Z","shell.execute_reply.started":"2023-11-04T08:15:29.850220Z","shell.execute_reply":"2023-11-04T08:25:11.021929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nfor i in [500,700,1000,1200]:\n    for k in [8,10,15]:\n        for  j in [0.6,0.8,1]:\n            for t in [0.8,1]:\n                lgb_md = LGBMRegressor(objective = 'mae', \n                                           n_estimators = i,\n                                           max_depth = k,\n                                           learning_rate = 0.01,\n                                           num_leaves = 105,\n                                           reg_alpha = 8,\n                                           reg_lambda = 3,\n                                           subsample = j,\n                                           colsample_bytree = t,\n                                           device = 'gpu').fit(X_train, Y_train)\n\n                lgb_pred_1 = lgb_md.predict(X_test[X_test['generated'] == 1])\n                lgb_pred_2 = lgb_md.predict(test_baseline)\n\n                lgb_score_fold = mean_absolute_error(Y_test[X_test['generated'] == 1], lgb_pred_1)    \n                lgb_cv_scores.append(lgb_score_fold)\n                lgb_preds.append(lgb_pred_2)\n                print('i=%d,k=%d，j=%.2f,t=%.2f,score=%.10f'%(i,k,j,t,lgb_score_fold))\n'''","metadata":{"execution":{"iopub.status.busy":"2023-11-04T10:42:11.387884Z","iopub.status.idle":"2023-11-04T10:42:11.388197Z","shell.execute_reply.started":"2023-11-04T10:42:11.388042Z","shell.execute_reply":"2023-11-04T10:42:11.388056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nfor i in [0.8,0.9,1]:\n    for j in[7,8,10,12]:\n        for k in [200,800,1000,1200]:\n            for t in [20,30,50]:\n                for g in [0.7,0.8,0.9,1]:\n                    xgb_md = XGBRegressor(objective = 'reg:pseudohubererror',\n                                              tree_method = 'gpu_hist',\n                                              colsample_bytree = i, \n                                              gamma = 0.65, \n                                              learning_rate = 0.01, \n                                              max_depth = j, \n                                              min_child_weight = t, \n                                              n_estimators = k, \n                                              subsample = g).fit(X_train, Y_train)\n\n                    xgb_pred_1 = xgb_md.predict(X_test[X_test['generated'] == 1])\n                    xgb_pred_2 = xgb_md.predict(test_baseline)\n\n                    xgb_score_fold = mean_absolute_error(Y_test[X_test['generated'] == 1], xgb_pred_1)    \n                    xgb_cv_scores.append(xgb_score_fold)\n                    xgb_preds.append(xgb_pred_2)\n                    print('i=%f,k=%d，j=%d,t=%d,g=%f,score=%.10f'%(i,k,j,t,g,xgb_score_fold))\n'''","metadata":{"execution":{"iopub.status.busy":"2023-11-04T08:58:40.952660Z","iopub.execute_input":"2023-11-04T08:58:40.953382Z","iopub.status.idle":"2023-11-04T09:32:13.757051Z","shell.execute_reply.started":"2023-11-04T08:58:40.953344Z","shell.execute_reply":"2023-11-04T09:32:13.756237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"7\"></a>\n# <h1 style=\"background-color:lightgray;font-family:newtimeroman;font-size:350%;text-align:center;border-radius: 15px 50px;\">Baseline Modeling 2.0</h1>\n\nIn this section, we improve baseline modeling 1.0 by adding a couple of engineered features and `CatBoost`. Notice that, a couple of the suggested engineered features from this [post](https://www.kaggle.com/competitions/playground-series-s3e16/discussion/415721).","metadata":{}},{"cell_type":"code","source":"X = train.drop(columns = ['Age'], axis = 1)\nY = train['Age']\n\nX['Meat Yield'] = X['Shucked Weight'] / (X['Weight'] + X['Shell Weight'])\nX['Shell Ratio'] = X['Shell Weight'] / X['Weight']\nX['Weight_to_Shucked_Weight'] = X['Weight'] / X['Shucked Weight']\nX['Viscera Ratio'] = X['Viscera Weight'] / X['Weight']\n\ntest_baseline = test.drop(columns = ['id'], axis = 1)\n\ntest_baseline['Sex'] = le.transform(test_baseline['Sex'])\ntest_baseline['Meat Yield'] = test_baseline['Shucked Weight'] / (test_baseline['Weight'] + test_baseline['Shell Weight'])\ntest_baseline['Shell Ratio'] = test_baseline['Shell Weight'] / test_baseline['Weight']\ntest_baseline['Weight_to_Shucked_Weight'] = test_baseline['Weight'] / test_baseline['Shucked Weight']\ntest_baseline['Viscera Ratio'] = test_baseline['Viscera Weight'] / test_baseline['Weight']\n\naml_cv_scores, aml_preds = list(), list()\ngb_cv_scores, gb_preds = list(), list()\nhist_cv_scores, hist_preds = list(), list()\nlgb_cv_scores, lgb_preds = list(), list()\nxgb_cv_scores, xgb_preds = list(), list()\ncat_cv_scores, cat_preds = list(), list()\nens_cv_scores_1, ens_preds_1 = list(), list()\nens_cv_scores_2, ens_preds_2 = list(), list()\nens_cv_scores_3, ens_preds_3 = list(), list()\nens_cv_scores_4, ens_preds_4 = list(), list()","metadata":{"execution":{"iopub.status.busy":"2023-11-08T14:19:34.694344Z","iopub.execute_input":"2023-11-08T14:19:34.694692Z","iopub.status.idle":"2023-11-08T14:19:34.732199Z","shell.execute_reply.started":"2023-11-08T14:19:34.694664Z","shell.execute_reply":"2023-11-08T14:19:34.731324Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"print(X['Sex'])","metadata":{"execution":{"iopub.status.busy":"2023-11-08T10:07:04.837933Z","iopub.execute_input":"2023-11-08T10:07:04.838670Z","iopub.status.idle":"2023-11-08T10:07:04.847502Z","shell.execute_reply.started":"2023-11-08T10:07:04.838626Z","shell.execute_reply":"2023-11-08T10:07:04.846260Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"0        1\n1        1\n2        2\n3        0\n4        1\n        ..\n77939    0\n77940    0\n77941    1\n77942    1\n77943    1\nName: Sex, Length: 77944, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"mask = (Y <= 19) & (Y >= 4)\nX_1 = X[mask]\nY_1 = Y[mask]\n\nfrom sklearn.model_selection import train_test_split\nX_train_1, X_test_1, Y_train_1, Y_test_1 = train_test_split(X_1, Y_1, test_size=0.1, random_state=42)\n\n\nxgb_md = XGBRegressor(objective = 'reg:pseudohubererror',\n                          tree_method = 'hist',\n                          colsample_bytree = 1, \n                          gamma = 0.65, \n                          learning_rate = 0.01, \n                          max_depth = 8, \n                          min_child_weight = 20, \n                          n_estimators = 1000,\n                          subsample = 0.7,\n                          random_state = 42).fit(X_train_gb, Y_train) \n    \nX_train_gb_1 = X_train_1[gb_features]\nX_test_gb_1 = X_test_1[gb_features]\ntest_baseline_gb = test_baseline[gb_features]\nxgb_pred_1 = xgb_md.predict(X_test_gb_1[X_test_gb_1['generated'] == 1])\n\n\nxgb_score_fold = mean_absolute_error(Y_test_1[X_test_gb_1['generated'] == 1], xgb_pred_1)    \nxgb_score_fold_2 = mean_absolute_error(Y_test_1[X_test_gb_1['generated'] == 1], np.round(xgb_pred_1)) \n\n\nprint(xgb_score_fold)\nprint(xgb_score_fold_2)","metadata":{"execution":{"iopub.status.busy":"2023-11-08T14:20:08.252685Z","iopub.execute_input":"2023-11-08T14:20:08.253150Z","iopub.status.idle":"2023-11-08T14:20:08.319250Z","shell.execute_reply.started":"2023-11-08T14:20:08.253111Z","shell.execute_reply":"2023-11-08T14:20:08.318055Z"},"trusted":true},"execution_count":13,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[13], line 18\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m      6\u001b[0m X_train_1, X_test_1, Y_train_1, Y_test_1 \u001b[38;5;241m=\u001b[39m train_test_split(X_1, Y_1, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      9\u001b[0m xgb_md \u001b[38;5;241m=\u001b[39m XGBRegressor(objective \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreg:pseudohubererror\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     10\u001b[0m                           tree_method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhist\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     11\u001b[0m                           colsample_bytree \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, \n\u001b[1;32m     12\u001b[0m                           gamma \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.65\u001b[39m, \n\u001b[1;32m     13\u001b[0m                           learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.01\u001b[39m, \n\u001b[1;32m     14\u001b[0m                           max_depth \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m, \n\u001b[1;32m     15\u001b[0m                           min_child_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m, \n\u001b[1;32m     16\u001b[0m                           n_estimators \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m,\n\u001b[1;32m     17\u001b[0m                           subsample \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.7\u001b[39m,\n\u001b[0;32m---> 18\u001b[0m                           random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m42\u001b[39m)\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_train_gb\u001b[49m, Y_train) \n\u001b[1;32m     20\u001b[0m X_train_gb_1 \u001b[38;5;241m=\u001b[39m X_train_1[gb_features]\n\u001b[1;32m     21\u001b[0m X_test_gb_1 \u001b[38;5;241m=\u001b[39m X_test_1[gb_features]\n","\u001b[0;31mNameError\u001b[0m: name 'X_train_gb' is not defined"],"ename":"NameError","evalue":"name 'X_train_gb' is not defined","output_type":"error"}]},{"cell_type":"code","source":"X_train, X_test = X.iloc[train_ix], X.iloc[test_ix]\nY_train, Y_test = Y.iloc[train_ix], Y.iloc[test_ix]\n\nprint('---------------------------------------------------------------')\n\n######################\n## GradientBoosting ##\n######################\n\ngb_features = ['Sex',\n               'Length',\n               'Diameter',\n               'Height',\n               'Weight',\n               'Shucked Weight',\n               'Viscera Weight',\n               'Shell Weight',\n               'generated']\n\nX_train_gb = X_train[gb_features]\nX_test_gb = X_test[gb_features]\ntest_baseline_gb = test_baseline[gb_features]\n\ngb_md = GradientBoostingRegressor(loss = 'absolute_error',\n                                  n_estimators = 1000, \n                                  max_depth = 8, \n                                  learning_rate = 0.01,\n                                  min_samples_split = 10, \n                                  min_samples_leaf = 20,\n                                  random_state = 42).fit(X_train_gb, Y_train) \n\ngb_pred_1 = gb_md.predict(X_test_gb[X_test_gb['generated'] == 1])\ngb_pred_2 = gb_md.predict(test_baseline_gb)\n\ngb_score_fold_1 = mean_absolute_error(Y_test[X_test_gb['generated'] == 1], gb_pred_1)\ngb_score_fold_2 = mean_absolute_error(Y_test[X_test_gb['generated'] == 1], np.round(gb_pred_1))\n\ngb_preds.append(gb_pred_2)\nprint(gb_score_fold_1)\nprint(gb_score_fold_2)\n    #print('Fold', i, '==> GradientBoositng oof MAE is ==>', gb_score_fold)","metadata":{"execution":{"iopub.status.busy":"2023-11-08T14:21:53.361571Z","iopub.execute_input":"2023-11-08T14:21:53.362360Z","iopub.status.idle":"2023-11-08T14:23:24.213862Z","shell.execute_reply.started":"2023-11-08T14:21:53.362329Z","shell.execute_reply":"2023-11-08T14:23:24.212543Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"---------------------------------------------------------------\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[16], line 30\u001b[0m\n\u001b[1;32m     21\u001b[0m X_test_gb \u001b[38;5;241m=\u001b[39m X_test[gb_features]\n\u001b[1;32m     22\u001b[0m test_baseline_gb \u001b[38;5;241m=\u001b[39m test_baseline[gb_features]\n\u001b[1;32m     24\u001b[0m gb_md \u001b[38;5;241m=\u001b[39m \u001b[43mGradientBoostingRegressor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mabsolute_error\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mmax_depth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mmin_samples_split\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mmin_samples_leaf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m---> 30\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_gb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     32\u001b[0m gb_pred_1 \u001b[38;5;241m=\u001b[39m gb_md\u001b[38;5;241m.\u001b[39mpredict(X_test_gb[X_test_gb[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerated\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     33\u001b[0m gb_pred_2 \u001b[38;5;241m=\u001b[39m gb_md\u001b[38;5;241m.\u001b[39mpredict(test_baseline_gb)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_gb.py:538\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resize_state()\n\u001b[1;32m    537\u001b[0m \u001b[38;5;66;03m# fit the boosting stages\u001b[39;00m\n\u001b[0;32m--> 538\u001b[0m n_stages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stages\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbegin_at_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;66;03m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[1;32m    552\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_stages \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_gb.py:615\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[1;32m    608\u001b[0m     old_oob_score \u001b[38;5;241m=\u001b[39m loss_(\n\u001b[1;32m    609\u001b[0m         y[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[1;32m    610\u001b[0m         raw_predictions[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[1;32m    611\u001b[0m         sample_weight[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[1;32m    612\u001b[0m     )\n\u001b[1;32m    614\u001b[0m \u001b[38;5;66;03m# fit next stage of trees\u001b[39;00m\n\u001b[0;32m--> 615\u001b[0m raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m    \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;66;03m# track deviance (= loss)\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_oob:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_gb.py:257\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    254\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;241m*\u001b[39m sample_mask\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m    256\u001b[0m X \u001b[38;5;241m=\u001b[39m X_csr \u001b[38;5;28;01mif\u001b[39;00m X_csr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n\u001b[0;32m--> 257\u001b[0m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# update tree leaves\u001b[39;00m\n\u001b[1;32m    260\u001b[0m loss\u001b[38;5;241m.\u001b[39mupdate_terminal_regions(\n\u001b[1;32m    261\u001b[0m     tree\u001b[38;5;241m.\u001b[39mtree_,\n\u001b[1;32m    262\u001b[0m     X,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    269\u001b[0m     k\u001b[38;5;241m=\u001b[39mk,\n\u001b[1;32m    270\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/tree/_classes.py:1247\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1219\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[1;32m   1220\u001b[0m \n\u001b[1;32m   1221\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1244\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1245\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1247\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1249\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1250\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/tree/_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    370\u001b[0m         splitter,\n\u001b[1;32m    371\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    377\u001b[0m     )\n\u001b[0;32m--> 379\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"print(max(gb_pred_2))\nprint(min(gb_pred_2))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"skf = KFold(n_splits = 10, random_state = 42, shuffle = True)\n\nfor i, (train_ix, test_ix) in enumerate(skf.split(X_1, Y_1)):\n    if i == 0:\n        train_ix = train_ix\n        test_ix = test_ix","metadata":{"execution":{"iopub.status.busy":"2023-11-08T14:21:50.154404Z","iopub.execute_input":"2023-11-08T14:21:50.154739Z","iopub.status.idle":"2023-11-08T14:21:50.168099Z","shell.execute_reply.started":"2023-11-08T14:21:50.154712Z","shell.execute_reply":"2023-11-08T14:21:50.167306Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"print(max(gb_pred_1))\nprint(min(gb_pred_1))","metadata":{"execution":{"iopub.status.busy":"2023-11-08T08:55:54.921146Z","iopub.execute_input":"2023-11-08T08:55:54.921878Z","iopub.status.idle":"2023-11-08T08:55:54.928695Z","shell.execute_reply.started":"2023-11-08T08:55:54.921848Z","shell.execute_reply":"2023-11-08T08:55:54.927611Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"18.984711392606197\n3.6399331824323955\n","output_type":"stream"}]},{"cell_type":"code","source":"print(max(xgb_pred_1))\nprint(min(xgb_pred_1))","metadata":{"execution":{"iopub.status.busy":"2023-11-08T09:14:15.888076Z","iopub.execute_input":"2023-11-08T09:14:15.888448Z","iopub.status.idle":"2023-11-08T09:14:15.895685Z","shell.execute_reply.started":"2023-11-08T09:14:15.888420Z","shell.execute_reply":"2023-11-08T09:14:15.894666Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"18.29166\n3.773691\n","output_type":"stream"}]},{"cell_type":"code","source":"xgb_md = XGBRegressor(objective = 'reg:pseudohubererror',\n                          tree_method = 'hist',\n                          colsample_bytree = 1, \n                          gamma = 0.65, \n                          learning_rate = 0.01, \n                          max_depth = 8, \n                          min_child_weight = 20, \n                          n_estimators = 1000,\n                          subsample = 0.7,\n                          random_state = 42).fit(X_train_gb, Y_train) \n    \nxgb_pred_1 = xgb_md.predict(X_test_gb[X_test_gb['generated'] == 1])\n\n\nxgb_score_fold = mean_absolute_error(Y_test[X_test_gb['generated'] == 1], xgb_pred_1)    \nxgb_score_fold_2 = mean_absolute_error(Y_test[X_test_gb['generated'] == 1], np.round(xgb_pred_1)) \n\n\nprint(xgb_score_fold)\nprint(xgb_score_fold_2)","metadata":{"execution":{"iopub.status.busy":"2023-11-08T14:23:41.511932Z","iopub.execute_input":"2023-11-08T14:23:41.512295Z","iopub.status.idle":"2023-11-08T14:23:46.068189Z","shell.execute_reply.started":"2023-11-08T14:23:41.512264Z","shell.execute_reply":"2023-11-08T14:23:46.067361Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"1.3531401612474645\n1.3241602590044517\n","output_type":"stream"}]},{"cell_type":"code","source":"xgb_pred_2 = xgb_md.predict(test_baseline_gb)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-08T14:25:15.926784Z","iopub.execute_input":"2023-11-08T14:25:15.927178Z","iopub.status.idle":"2023-11-08T14:25:16.507230Z","shell.execute_reply.started":"2023-11-08T14:25:15.927142Z","shell.execute_reply":"2023-11-08T14:25:16.506433Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"print(max(xgb_pred_2))\nprint(min(xgb_pred_2))","metadata":{"execution":{"iopub.status.busy":"2023-11-08T14:25:29.669570Z","iopub.execute_input":"2023-11-08T14:25:29.670508Z","iopub.status.idle":"2023-11-08T14:25:29.688027Z","shell.execute_reply.started":"2023-11-08T14:25:29.670472Z","shell.execute_reply":"2023-11-08T14:25:29.687012Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"19.812178\n3.7428784\n","output_type":"stream"}]},{"cell_type":"code","source":"hist_md = HistGradientBoostingRegressor(loss = 'absolute_error',\n                                            l2_regularization = 0.01,\n                                            early_stopping = False,\n                                            learning_rate = 0.01,\n                                            max_iter = 1000,\n                                            max_depth = 15,\n                                            max_bins = 255,\n                                            min_samples_leaf = 100,\n                                            max_leaf_nodes = 70,\n                                            random_state = 42).fit(X_train, Y_train) \n    \nhist_pred_1 = hist_md.predict(X_test[X_test['generated'] == 1])\nhist_pred_2 = hist_md.predict(test_baseline)\n\nhist_score_fold = mean_absolute_error(Y_test[X_test['generated'] == 1], hist_pred_1)\n\nprint(max(hist_pred_1))\nprint(min(hist_pred_1))","metadata":{"execution":{"iopub.status.busy":"2023-11-08T09:15:59.604466Z","iopub.execute_input":"2023-11-08T09:15:59.605181Z","iopub.status.idle":"2023-11-08T09:16:29.606568Z","shell.execute_reply.started":"2023-11-08T09:15:59.605153Z","shell.execute_reply":"2023-11-08T09:16:29.605550Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"18.281638491421948\n3.9959701405784087\n","output_type":"stream"}]},{"cell_type":"code","source":"lgb_md = LGBMRegressor(objective = 'mae', \n                           n_estimators = 1200,\n                           max_depth = 10,\n                           learning_rate = 0.01,\n                           num_leaves = 105, \n                           reg_alpha = 8, \n                           reg_lambda = 3, \n                           subsample = 0.8, \n                           colsample_bytree = 0.8,\n                           random_state = 42).fit(X_train, Y_train)\n    \nlgb_pred_1 = lgb_md.predict(X_test[X_test['generated'] == 1])\nlgb_pred_2 = lgb_md.predict(test_baseline)\n\nlgb_score_fold = mean_absolute_error(Y_test[X_test['generated'] == 1], lgb_pred_1)    \n\n\nprint(max(lgb_pred_2))\nprint(min(lgb_pred_2))","metadata":{"execution":{"iopub.status.busy":"2023-11-08T09:16:50.145646Z","iopub.execute_input":"2023-11-08T09:16:50.146348Z","iopub.status.idle":"2023-11-08T09:17:04.775147Z","shell.execute_reply.started":"2023-11-08T09:16:50.146306Z","shell.execute_reply":"2023-11-08T09:17:04.774367Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"18.74501251332373\n3.9356159331343057\n","output_type":"stream"}]},{"cell_type":"code","source":"print(max(lgb_pred_2))\nprint(min(lgb_pred_2))","metadata":{"execution":{"iopub.status.busy":"2023-11-08T14:18:26.935690Z","iopub.execute_input":"2023-11-08T14:18:26.936026Z","iopub.status.idle":"2023-11-08T14:18:26.965327Z","shell.execute_reply.started":"2023-11-08T14:18:26.935996Z","shell.execute_reply":"2023-11-08T14:18:26.963854Z"},"trusted":true},"execution_count":3,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mmax\u001b[39m(\u001b[43mlgb_pred_2\u001b[49m))\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mmin\u001b[39m(lgb_pred_2))\n","\u001b[0;31mNameError\u001b[0m: name 'lgb_pred_2' is not defined"],"ename":"NameError","evalue":"name 'lgb_pred_2' is not defined","output_type":"error"}]},{"cell_type":"code","source":"'''\nX = train.drop(columns = ['Age'], axis = 1)\nY = train['Age']\n\nX['Meat Yield'] = X['Shucked Weight'] / (X['Weight'] + X['Shell Weight'])\nX['Shell Ratio'] = X['Shell Weight'] / X['Weight']\nX['Weight_to_Shucked_Weight'] = X['Weight'] / X['Shucked Weight']\nX['Viscera Ratio'] = X['Viscera Weight'] / X['Weight']\n\ntest_baseline = test.drop(columns = ['id'], axis = 1)\n\ntest_baseline['Sex'] = le.transform(test_baseline['Sex'])\ntest_baseline['Meat Yield'] = test_baseline['Shucked Weight'] / (test_baseline['Weight'] + test_baseline['Shell Weight'])\ntest_baseline['Shell Ratio'] = test_baseline['Shell Weight'] / test_baseline['Weight']\ntest_baseline['Weight_to_Shucked_Weight'] = test_baseline['Weight'] / test_baseline['Shucked Weight']\ntest_baseline['Viscera Ratio'] = test_baseline['Viscera Weight'] / test_baseline['Weight']\n\naml_cv_scores, aml_preds = list(), list()\ngb_cv_scores, gb_preds = list(), list()\nhist_cv_scores, hist_preds = list(), list()\nlgb_cv_scores, lgb_preds = list(), list()\nxgb_cv_scores, xgb_preds = list(), list()\ncat_cv_scores, cat_preds = list(), list()\nens_cv_scores_1, ens_preds_1 = list(), list()\nens_cv_scores_2, ens_preds_2 = list(), list()\nens_cv_scores_3, ens_preds_3 = list(), list()\nens_cv_scores_4, ens_preds_4 = list(), list()\n'''\nskf = KFold(n_splits = 10, random_state = 42, shuffle = True)\n\nfor i, (train_ix, test_ix) in enumerate(skf.split(X_1, Y_1)):\n        \n    X_train, X_test = X.iloc[train_ix], X.iloc[test_ix]\n    Y_train, Y_test = Y.iloc[train_ix], Y.iloc[test_ix]\n    \n    print('---------------------------------------------------------------')\n    \n    ######################\n    ## GradientBoosting ##\n    ######################\n    \n    gb_features = ['Sex',\n                   'Length',\n                   'Diameter',\n                   'Height',\n                   'Weight',\n                   'Shucked Weight',\n                   'Viscera Weight',\n                   'Shell Weight',\n                   'generated']\n    \n    X_train_gb = X_train[gb_features]\n    X_test_gb = X_test[gb_features]\n    test_baseline_gb = test_baseline[gb_features]\n    \n    gb_md = GradientBoostingRegressor(loss = 'absolute_error',\n                                      n_estimators = 1000, \n                                      max_depth = 8, \n                                      learning_rate = 0.01,\n                                      min_samples_split = 10, \n                                      min_samples_leaf = 20,\n                                      random_state = 42).fit(X_train_gb, Y_train) \n    \n    gb_pred_1 = gb_md.predict(X_test_gb[X_test_gb['generated'] == 1])\n    gb_pred_2 = gb_md.predict(test_baseline_gb)\n            \n    gb_score_fold = mean_absolute_error(Y_test[X_test_gb['generated'] == 1], gb_pred_1)\n    gb_cv_scores.append(gb_score_fold)\n    gb_preds.append(gb_pred_2)\n    \n    print('Fold', i, '==> GradientBoositng oof MAE is ==>', gb_score_fold)\n    \n    \n    ##########################\n    ## HistGradientBoosting ##\n    ##########################\n        \n    hist_md = HistGradientBoostingRegressor(loss = 'absolute_error',\n                                            l2_regularization = 0.01,\n                                            early_stopping = False,\n                                            learning_rate = 0.01,\n                                            max_iter = 1000,\n                                            max_depth = 15,\n                                            max_bins = 255,\n                                            min_samples_leaf = 100,\n                                            max_leaf_nodes = 70,\n                                            random_state = 42).fit(X_train, Y_train) \n    \n    hist_pred_1 = hist_md.predict(X_test[X_test['generated'] == 1])\n    hist_pred_2 = hist_md.predict(test_baseline)\n\n    hist_score_fold = mean_absolute_error(Y_test[X_test['generated'] == 1], hist_pred_1)\n    hist_cv_scores.append(hist_score_fold)\n    hist_preds.append(hist_pred_2)\n    \n    print('Fold', i, '==> HistGradient oof MAE is ==>', hist_score_fold)\n        \n    ##############\n    ## LightGBM ##\n    ##############\n        \n    lgb_md = LGBMRegressor(objective = 'mae', \n                           n_estimators = 1200,\n                           max_depth = 10,\n                           learning_rate = 0.01,\n                           num_leaves = 105, \n                           reg_alpha = 8, \n                           reg_lambda = 3, \n                           subsample = 0.8, \n                           colsample_bytree = 0.8,\n                           random_state = 42).fit(X_train, Y_train)\n    \n    lgb_pred_1 = lgb_md.predict(X_test[X_test['generated'] == 1])\n    lgb_pred_2 = lgb_md.predict(test_baseline)\n\n    lgb_score_fold = mean_absolute_error(Y_test[X_test['generated'] == 1], lgb_pred_1)    \n    lgb_cv_scores.append(lgb_score_fold)\n    lgb_preds.append(lgb_pred_2)\n    \n    print('Fold', i, '==> LightGBM oof MAE is ==>', lgb_score_fold)\n        \n    #############\n    ## XGBoost ##\n    #############\n    \n    xgb_md = XGBRegressor(objective = 'reg:pseudohubererror',\n                          tree_method = 'hist',\n                          colsample_bytree = 1, \n                          gamma = 0.65, \n                          learning_rate = 0.01, \n                          max_depth = 8, \n                          min_child_weight = 20, \n                          n_estimators = 1000,\n                          subsample = 0.7,\n                          random_state = 42).fit(X_train_gb, Y_train) \n    \n    xgb_pred_1 = xgb_md.predict(X_test_gb[X_test_gb['generated'] == 1])\n    xgb_pred_2 = xgb_md.predict(test_baseline_gb)\n\n    xgb_score_fold = mean_absolute_error(Y_test[X_test_gb['generated'] == 1], xgb_pred_1)    \n    xgb_cv_scores.append(xgb_score_fold)\n    xgb_preds.append(xgb_pred_2)\n    \n    print('Fold', i, '==> XGBoost oof MAE is ==>', xgb_score_fold)\n    \n    \n    \n   \n    \n    \n    ##################\n    ## LAD Ensemble ##\n    ##################\n    \n    x = pd.DataFrame({'GBC': np.round(gb_pred_1.tolist()),  'hist': np.round(hist_pred_1.tolist()), \n                      'lgb': np.round(lgb_pred_1.tolist()), 'xgb': np.round(xgb_pred_1.tolist())\n                      })\n    y = Y_test[X_test['generated'] == 1]\n    \n    x_test = pd.DataFrame({'GBC': np.round(gb_pred_2.tolist()),  'hist': np.round(hist_pred_2.tolist()), \n                           'lgb': np.round(lgb_pred_2.tolist()), 'xgb': np.round(xgb_pred_2.tolist()), \n                           })\n    \n    lad_md_1 = LADRegression(fit_intercept = True, positive = False).fit(x, y)\n    lad_md_2 = LADRegression(fit_intercept = True, positive = True).fit(x, y)\n    lad_md_3 = LADRegression(fit_intercept = False, positive = True).fit(x, y)\n    lad_md_4 = LADRegression(fit_intercept = False, positive = False).fit(x, y)\n    \n    lad_pred_1 = lad_md_1.predict(x)\n    lad_pred_2 = lad_md_2.predict(x)\n    lad_pred_3 = lad_md_3.predict(x)\n    lad_pred_4 = lad_md_4.predict(x)\n    \n    lad_pred_test_1 = lad_md_1.predict(x_test)\n    lad_pred_test_2 = lad_md_2.predict(x_test)\n    lad_pred_test_3 = lad_md_3.predict(x_test)\n    lad_pred_test_4 = lad_md_4.predict(x_test)\n        \n    ens_score_1 = mean_absolute_error(y, lad_pred_1)\n    ens_cv_scores_1.append(ens_score_1)\n    ens_preds_1.append(lad_pred_test_1)\n    \n    ens_score_2 = mean_absolute_error(y, lad_pred_2)\n    ens_cv_scores_2.append(ens_score_2)\n    ens_preds_2.append(lad_pred_test_2)\n    \n    ens_score_3 = mean_absolute_error(y, lad_pred_3)\n    ens_cv_scores_3.append(ens_score_3)\n    ens_preds_3.append(lad_pred_test_3)\n    \n    ens_score_4 = mean_absolute_error(y, lad_pred_4)\n    ens_cv_scores_4.append(ens_score_4)\n    ens_preds_4.append(lad_pred_test_4)\n    \n    print('Fold', i, '==> LAD Model 1 ensemble oof MAE is ==>', ens_score_1)\n    print('Fold', i, '==> LAD Model 2 ensemble oof MAE is ==>', ens_score_2)\n    print('Fold', i, '==> LAD Model 3 ensemble oof MAE is ==>', ens_score_3)\n    print('Fold', i, '==> LAD Model 4 ensemble oof MAE is ==>', ens_score_4)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-08T09:20:15.506337Z","iopub.execute_input":"2023-11-08T09:20:15.506739Z","iopub.status.idle":"2023-11-08T10:07:04.835503Z","shell.execute_reply.started":"2023-11-08T09:20:15.506711Z","shell.execute_reply":"2023-11-08T10:07:04.834190Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"---------------------------------------------------------------\nFold 0 ==> GradientBoositng oof MAE is ==> 1.3489326058430415\nFold 0 ==> HistGradient oof MAE is ==> 1.3440783564302452\nFold 0 ==> LightGBM oof MAE is ==> 1.3419025703311969\nFold 0 ==> XGBoost oof MAE is ==> 1.3543843457756033\nFold 0 ==> LAD Model 1 ensemble oof MAE is ==> 1.3250202212355822\nFold 0 ==> LAD Model 2 ensemble oof MAE is ==> 1.325020221123636\nFold 0 ==> LAD Model 3 ensemble oof MAE is ==> 1.3250202210838566\nFold 0 ==> LAD Model 4 ensemble oof MAE is ==> 1.325020221499828\n---------------------------------------------------------------\nFold 1 ==> GradientBoositng oof MAE is ==> 1.3826250183449893\nFold 1 ==> HistGradient oof MAE is ==> 1.3862933073112091\nFold 1 ==> LightGBM oof MAE is ==> 1.379667057932577\nFold 1 ==> XGBoost oof MAE is ==> 1.3912427103448826\nFold 1 ==> LAD Model 1 ensemble oof MAE is ==> 1.3637587517438314\nFold 1 ==> LAD Model 2 ensemble oof MAE is ==> 1.3637587506734392\nFold 1 ==> LAD Model 3 ensemble oof MAE is ==> 1.3637587506731321\nFold 1 ==> LAD Model 4 ensemble oof MAE is ==> 1.3637587516407614\n---------------------------------------------------------------\nFold 2 ==> GradientBoositng oof MAE is ==> 1.3606749919092713\nFold 2 ==> HistGradient oof MAE is ==> 1.3619033367201194\nFold 2 ==> LightGBM oof MAE is ==> 1.3540639403779098\nFold 2 ==> XGBoost oof MAE is ==> 1.365408280420871\nFold 2 ==> LAD Model 1 ensemble oof MAE is ==> 1.335362554114206\nFold 2 ==> LAD Model 2 ensemble oof MAE is ==> 1.335362554112592\nFold 2 ==> LAD Model 3 ensemble oof MAE is ==> 1.3353625541125693\nFold 2 ==> LAD Model 4 ensemble oof MAE is ==> 1.335362554113652\n---------------------------------------------------------------\nFold 3 ==> GradientBoositng oof MAE is ==> 1.332932997141231\nFold 3 ==> HistGradient oof MAE is ==> 1.3344126156111404\nFold 3 ==> LightGBM oof MAE is ==> 1.3285696399724611\nFold 3 ==> XGBoost oof MAE is ==> 1.3399532076347718\nFold 3 ==> LAD Model 1 ensemble oof MAE is ==> 1.3096974608795624\nFold 3 ==> LAD Model 2 ensemble oof MAE is ==> 1.3096974608319842\nFold 3 ==> LAD Model 3 ensemble oof MAE is ==> 1.3096974608319827\nFold 3 ==> LAD Model 4 ensemble oof MAE is ==> 1.309697460833608\n---------------------------------------------------------------\nFold 4 ==> GradientBoositng oof MAE is ==> 1.3180850740920165\nFold 4 ==> HistGradient oof MAE is ==> 1.312352170627065\nFold 4 ==> LightGBM oof MAE is ==> 1.3111940953334325\nFold 4 ==> XGBoost oof MAE is ==> 1.3268524389628307\nFold 4 ==> LAD Model 1 ensemble oof MAE is ==> 1.2945872801251204\nFold 4 ==> LAD Model 2 ensemble oof MAE is ==> 1.294587280108255\nFold 4 ==> LAD Model 3 ensemble oof MAE is ==> 1.2945872801082543\nFold 4 ==> LAD Model 4 ensemble oof MAE is ==> 1.294587280108311\n---------------------------------------------------------------\nFold 5 ==> GradientBoositng oof MAE is ==> 1.3604542721121695\nFold 5 ==> HistGradient oof MAE is ==> 1.3561922326926876\nFold 5 ==> LightGBM oof MAE is ==> 1.3592706545382613\nFold 5 ==> XGBoost oof MAE is ==> 1.3751472293374545\nFold 5 ==> LAD Model 1 ensemble oof MAE is ==> 1.3411604191698425\nFold 5 ==> LAD Model 2 ensemble oof MAE is ==> 1.34115111197194\nFold 5 ==> LAD Model 3 ensemble oof MAE is ==> 1.3411510985676787\nFold 5 ==> LAD Model 4 ensemble oof MAE is ==> 1.34115111042297\n---------------------------------------------------------------\nFold 6 ==> GradientBoositng oof MAE is ==> 1.4024483046587237\nFold 6 ==> HistGradient oof MAE is ==> 1.4049214080845345\nFold 6 ==> LightGBM oof MAE is ==> 1.3992702815789133\nFold 6 ==> XGBoost oof MAE is ==> 1.4039178685022728\nFold 6 ==> LAD Model 1 ensemble oof MAE is ==> 1.3760140616550403\nFold 6 ==> LAD Model 2 ensemble oof MAE is ==> 1.3760140616549534\nFold 6 ==> LAD Model 3 ensemble oof MAE is ==> 1.3760140616549492\nFold 6 ==> LAD Model 4 ensemble oof MAE is ==> 1.3760140616550194\n---------------------------------------------------------------\nFold 7 ==> GradientBoositng oof MAE is ==> 1.3681204994107228\nFold 7 ==> HistGradient oof MAE is ==> 1.37487333166954\nFold 7 ==> LightGBM oof MAE is ==> 1.3662264306391858\nFold 7 ==> XGBoost oof MAE is ==> 1.3778574767192215\nFold 7 ==> LAD Model 1 ensemble oof MAE is ==> 1.3477435967184377\nFold 7 ==> LAD Model 2 ensemble oof MAE is ==> 1.3477435966933584\nFold 7 ==> LAD Model 3 ensemble oof MAE is ==> 1.347743596693952\nFold 7 ==> LAD Model 4 ensemble oof MAE is ==> 1.3477435968931424\n---------------------------------------------------------------\nFold 8 ==> GradientBoositng oof MAE is ==> 1.3376154480249014\nFold 8 ==> HistGradient oof MAE is ==> 1.334987423713544\nFold 8 ==> LightGBM oof MAE is ==> 1.331222448387171\nFold 8 ==> XGBoost oof MAE is ==> 1.342756687854987\nFold 8 ==> LAD Model 1 ensemble oof MAE is ==> 1.3144903024827432\nFold 8 ==> LAD Model 2 ensemble oof MAE is ==> 1.314490016198347\nFold 8 ==> LAD Model 3 ensemble oof MAE is ==> 1.3144900161899646\nFold 8 ==> LAD Model 4 ensemble oof MAE is ==> 1.3144900202835472\n---------------------------------------------------------------\nFold 9 ==> GradientBoositng oof MAE is ==> 1.3415450901897583\nFold 9 ==> HistGradient oof MAE is ==> 1.347358828112607\nFold 9 ==> LightGBM oof MAE is ==> 1.3467030990602\nFold 9 ==> XGBoost oof MAE is ==> 1.3531401612474645\nFold 9 ==> LAD Model 1 ensemble oof MAE is ==> 1.3236206663968753\nFold 9 ==> LAD Model 2 ensemble oof MAE is ==> 1.3236206663968706\nFold 9 ==> LAD Model 3 ensemble oof MAE is ==> 1.3236206663968708\nFold 9 ==> LAD Model 4 ensemble oof MAE is ==> 1.3236206663968708\n","output_type":"stream"}]},{"cell_type":"code","source":"gb_cv_scores=[1.3489326058430415,1.3415450901897583,1.3376154480249014,1.3681204994107228,1.4024483046587237,1.3604542721121695,1.3180850740920165,1.332932997141231,1.3606749919092713,1.3826250183449893]","metadata":{"execution":{"iopub.status.busy":"2023-11-08T14:28:23.606023Z","iopub.execute_input":"2023-11-08T14:28:23.606462Z","iopub.status.idle":"2023-11-08T14:28:23.612496Z","shell.execute_reply.started":"2023-11-08T14:28:23.606426Z","shell.execute_reply":"2023-11-08T14:28:23.611416Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"print(np.mean(gb_cv_scores))","metadata":{"execution":{"iopub.status.busy":"2023-11-08T14:28:38.005580Z","iopub.execute_input":"2023-11-08T14:28:38.005931Z","iopub.status.idle":"2023-11-08T14:28:38.011013Z","shell.execute_reply.started":"2023-11-08T14:28:38.005902Z","shell.execute_reply":"2023-11-08T14:28:38.010112Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"1.3553434301726823\n","output_type":"stream"}]},{"cell_type":"code","source":"hist_cv_scores = [1.347358828112607,1.334987423713544,1.37487333166954,1.4049214080845345,1.3561922326926876,1.312352170627065,1.3344126156111404,1.3619033367201194,1.3862933073112091,1.3440783564302452]","metadata":{"execution":{"iopub.status.busy":"2023-11-08T14:31:54.269187Z","iopub.execute_input":"2023-11-08T14:31:54.269536Z","iopub.status.idle":"2023-11-08T14:31:54.274349Z","shell.execute_reply.started":"2023-11-08T14:31:54.269508Z","shell.execute_reply":"2023-11-08T14:31:54.273454Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"print(np.mean(hist_cv_scores))","metadata":{"execution":{"iopub.status.busy":"2023-11-08T14:32:08.652647Z","iopub.execute_input":"2023-11-08T14:32:08.653008Z","iopub.status.idle":"2023-11-08T14:32:08.658464Z","shell.execute_reply.started":"2023-11-08T14:32:08.652976Z","shell.execute_reply":"2023-11-08T14:32:08.657434Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"1.3557373010972693\n","output_type":"stream"}]},{"cell_type":"code","source":"gb_cv_score = np.mean(gb_cv_scores)\nhist_cv_score = np.mean(hist_cv_scores)\nlgb_cv_score = np.mean(lgb_cv_scores)\nxgb_cv_score = np.mean(xgb_cv_scores)\nens_cv_score_1 = np.mean(ens_cv_scores_1)\nens_cv_score_2 = np.mean(ens_cv_scores_2)\nens_cv_score_3 = np.mean(ens_cv_scores_3)\nens_cv_score_4 = np.mean(ens_cv_scores_4)\n\nmodel_perf = pd.DataFrame({'Model': ['GradientBoosting', 'HistGradient' ,'LightGBM', 'XGBoost', \n                                     'LDA Model 1',\n                                     'LDA Model 2',\n                                     'LDA Model 3',\n                                     'LDA Model 4'],\n                           'cv-score': [gb_cv_score, hist_cv_score, lgb_cv_score, xgb_cv_score, \n                                        ens_cv_score_1,\n                                        ens_cv_score_2,\n                                        ens_cv_score_3,\n                                        ens_cv_score_4]})\n\nplt.figure(figsize = (8, 8))\nax = sns.barplot(y = 'Model', x = 'cv-score', data = model_perf)\nax.bar_label(ax.containers[0]);","metadata":{"execution":{"iopub.status.busy":"2023-11-08T14:25:39.929940Z","iopub.execute_input":"2023-11-08T14:25:39.930804Z","iopub.status.idle":"2023-11-08T14:25:40.284935Z","shell.execute_reply.started":"2023-11-08T14:25:39.930770Z","shell.execute_reply":"2023-11-08T14:25:40.283993Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n  return _methods._mean(a, axis=axis, dtype=dtype,\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n  ret = ret.dtype.type(ret / rcount)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 800x800 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"ens_preds_test_1 = pd.DataFrame(ens_preds_1).apply(np.mean, axis = 0)\nens_preds_test_2 = pd.DataFrame(ens_preds_2).apply(np.mean, axis = 0)\nens_preds_test_3 = pd.DataFrame(ens_preds_3).apply(np.mean, axis = 0)\nens_preds_test_4 = pd.DataFrame(ens_preds_4).apply(np.mean, axis = 0)\n\nsubmission['Age'] = round(ens_preds_test_1).astype(int)\nsubmission.to_csv('LAD_Ensemble_model_1.csv', index = False)\n\nsubmission['Age'] = round(ens_preds_test_2).astype(int)\nsubmission.to_csv('LAD_Ensemble_model_2.csv', index = False)\n\nsubmission['Age'] = round(ens_preds_test_3).astype(int)\nsubmission.to_csv('LAD_Ensemble_model_3.csv', index = False)\n\nsubmission['Age'] = round(ens_preds_test_4).astype(int)\nsubmission.to_csv('LAD_Ensemble_model_4.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2023-11-04T12:16:17.985686Z","iopub.execute_input":"2023-11-04T12:16:17.986424Z","iopub.status.idle":"2023-11-04T12:16:44.534472Z","shell.execute_reply.started":"2023-11-04T12:16:17.986386Z","shell.execute_reply":"2023-11-04T12:16:44.533634Z"},"trusted":true},"execution_count":null,"outputs":[]}]}